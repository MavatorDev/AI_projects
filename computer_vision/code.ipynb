{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8da456f8",
   "metadata": {},
   "source": [
    "\n",
    "## Coursework 1\n",
    "## Introduction to computer vision\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b846a1ba",
   "metadata": {},
   "source": [
    "#### Point 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb738255-9582-4e65-a02d-0541e8ce0851",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f701876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697fad51",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread('my_name.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2248db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(path):\n",
    "    img=cv2.imread(path)\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152c7199",
   "metadata": {},
   "source": [
    "#### 1.B Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f44461",
   "metadata": {},
   "source": [
    "**Rotated Images**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c9e96f-693e-479d-850a-a648e8837949",
   "metadata": {},
   "source": [
    "The first transformation to the image is the rotation. To achieve this, I have defined 3 methods\n",
    "\n",
    "The first method is Interpolate, which is used when forward mapping is applied (you can set the mapping preference). Basically, this method applies the median kernel to avoid black pixels in the output image. \n",
    "\n",
    "\n",
    "This is a helper method, you don't need to interact with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d291b20-b70c-4faf-8447-6691d46bcfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This method applies the median filter\n",
    "def ICV_interpolate(img):\n",
    "    #first the height and weight of the kernel and the image are stored in variables\n",
    "    w_kernel,h_kernel = 3, 3\n",
    "    w_img,h_img = len(img),len(img[0])\n",
    "    #A matrix with the same dimensions than the input image is created\n",
    "    new_img = np.zeros_like(img)\n",
    "    #Iteration starts from column and row 1 and finishes in size of the image - 1\n",
    "    for i in range(1,w_img-1):\n",
    "        for j in range(1,h_img-1):\n",
    "            #Every pixel is replaced with the median value found in the 3x3 matrix around\n",
    "            new_img[i,j,0] = np.median(img[i-1:i+2, j-1:j+2,0])\n",
    "            new_img[i,j,1] = np.median(img[i-1:i+2, j-1:j+2,1])\n",
    "            new_img[i,j,2] = np.median(img[i-1:i+2, j-1:j+2,2])\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baabcc0f-f5fc-4a10-bc8d-cb51a9f6a64d",
   "metadata": {},
   "source": [
    "When rotating the image, some data may be lost because the length of the image is insufficient. The following method was developed to avoid this. Basically, it calculates the diagonal of the image and compares it to the length of the image. This might increase the execution time of the rotation method, but it ensures that all information is preserved.\n",
    "\n",
    "\n",
    "This is a helper method, you don't need to interact with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd7a302",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_add_borders(img):\n",
    "    #The diagonal of the image is calculated (max possible length and width)\n",
    "    c = np.sqrt(len(img[0])**2+len(img)**2)\n",
    "    #If the width or height are smaller than the diagonal, the missing border is added to the image.\n",
    "    borders = np.zeros_like(img[0:int((c-len(img))/2),:,:])\n",
    "    img=np.vstack((borders,img,borders))\n",
    "    bordersh = np.zeros_like(img[:,0:int((c-len(img[0]))/2),:])\n",
    "    img=np.hstack((bordersh,img,bordersh))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0231083-2e85-4321-8d63-c00ecbd34cad",
   "metadata": {},
   "source": [
    "Now, the rotation method is defined with the following parameters:\n",
    "\n",
    "**Img**: the image to rotate in RGB or BGR format.\n",
    "\n",
    "\n",
    "**Angle**: Angle to be rotated, must be in degrees.\n",
    "\n",
    "\n",
    "**Inverse**: A flag to define the mapping method, by default inverse mapping is used.\n",
    "\n",
    "This method basically multiplies each position of the input image by the rotation matrix defined in the class to obtain the output values and finally maps them using the selected mapping method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573b65a4-5e04-4947-be07-fcc6c5b4ed72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_rotate(img,angle,inverse=True):\n",
    "    #adding borders to avoid losing pixels when transforming\n",
    "    img=ICV_add_borders(img)\n",
    "    #in case of inverse mapping it is necessary to take the negative angle\n",
    "    if inverse:\n",
    "        angle=-angle\n",
    "    #Numpy works with the angle in radians, and the input is a value in degrees\n",
    "    angle=np.deg2rad(angle)\n",
    "    #Rotation matrix is defined and a matrix with the same dimensions than the image is created\n",
    "    rot_matrix=[[np.cos(angle), -np.sin(angle)],\n",
    "        [np.sin(angle), np.cos(angle)]]\n",
    "    rotated=np.zeros_like(img)\n",
    "    center=len(img)//2\n",
    "    center_y=len(img[0])//2\n",
    "    #The origin is defined in the center of the image\n",
    "    for i in range(-center,center):\n",
    "        for j in range(-center_y,center_y):\n",
    "            #Each position is multiply by the rotation matrix defined to get the transformed position\n",
    "            new_pos = np.dot(rot_matrix,np.array([[i],[j]]))\n",
    "            new_pos_x=np.int_(new_pos[0])\n",
    "            new_pos_y=np.int_(new_pos[1])\n",
    "            \n",
    "            if 0 <= new_pos_x+center and new_pos_x+center < len(img) and 0 <= new_pos_y+center_y and new_pos_y+center_y< len(img[0]):\n",
    "                if inverse:\n",
    "                    #In case of inverse mapping, searches for the calculated position into the input image and assigns its value to the output\n",
    "                    rotated[i+center,j+center_y]=img[new_pos_x+center,new_pos_y+center_y]\n",
    "                else:\n",
    "                    #In case of forward mapping, assigns the value from the input to the calculated position in the output\n",
    "                    rotated[new_pos_x+center,new_pos_y+center_y]=img[i+center,j+center_y]\n",
    "    if inverse:\n",
    "        return rotated\n",
    "    else:\n",
    "        return ICV_interpolate(rotated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659b2006",
   "metadata": {},
   "source": [
    "\n",
    "Next line can be used to execute the forward mapping rotation, i'm not executing it to avoid innecesary iterations. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fb95d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv2.imwrite(\"fordward_median_rotated_30.jpg\",ICV_rotate(img,30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c722f8d0",
   "metadata": {},
   "source": [
    "Rotation by using inverse mapping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6293e2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(\"inverse_rot_30.jpg\",ICV_rotate(img,30,True))\n",
    "#plt.imshow(read_img(\"inverse_rot_30.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6679c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(\"inverse_rot_60.jpg\",ICV_rotate(img,60,True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a885cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(\"inverse_rot_120.jpg\",ICV_rotate(img,120,True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dc74b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(\"inverse_rot_-50.jpg\",ICV_rotate(img,-50,True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dab261d",
   "metadata": {},
   "source": [
    "#### Skewed Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94106d64-69dd-4c5c-8cea-e0e63b0ac1b9",
   "metadata": {},
   "source": [
    "The second transformation is the skew, which consists of moving the image along the horizontal direction while the vertical side remains fixed.\n",
    "\n",
    "Two methods have been defined to achieve this.\n",
    "\n",
    "As with the previous transformation, it must be ensured that no information is lost. Therefore, some borders are added to the input image, but this time, the angle defines how many pixels are going to be added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6a1a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_add_skew_borders(img,angle):\n",
    "    #calculate the additional columns needed by getting the length of the triangle that will be formed after the transformation.\n",
    "    c = len(img[0])/np.tan(angle)\n",
    "    bordersh = np.zeros_like(img[:,0:int((c)),:])\n",
    "    img=np.hstack((bordersh,img))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fac4fce-2a17-4c95-8a5c-758edcd940a0",
   "metadata": {},
   "source": [
    "To skew horizontally an image, next method should be executed with an image and an angle in degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c520bb5-724a-41e5-b261-3f3e6f43b1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_skew_horizontally(img,angle):\n",
    "    #Transformation are applied to the edges, so, our origin angle is 90\n",
    "    angle=90+angle\n",
    "    border_angle = 180-angle\n",
    "    angle=np.deg2rad(angle)\n",
    "    #add additional borders to the image\n",
    "    img = ICV_add_skew_borders(img,-angle)\n",
    "    skewed=np.zeros_like(img)\n",
    "    #defines the shear matrix\n",
    "    skew_matrix=[\n",
    "        [1, 1/np.tan(angle)],\n",
    "        [1/np.tan(angle), 1]\n",
    "    ]\n",
    "    width,height=len(img),len(img[0])\n",
    "    #starts iterating over all the pixels\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            new_pos = np.dot(skew_matrix,np.array([[x],[y]]))\n",
    "            #computes the new position\n",
    "            new_x=np.int_(new_pos[0])\n",
    "            new_y=np.int_(new_pos[1])\n",
    "            \n",
    "            if 0 <= new_y and new_y < height:\n",
    "                skewed[x,new_y]=img[x,y]\n",
    "    return skewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7f2438",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(\"inverse_skew_10.jpg\",ICV_skew_horizontally(img,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f41da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(\"inverse_skew_40.jpg\",ICV_skew_horizontally(img,40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b122995",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(\"inverse_skew_60.jpg\",ICV_skew_horizontally(img,60))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2438fc",
   "metadata": {},
   "source": [
    "Rotation and Skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40856924",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_rotated_before_skewed_img(img,rotation_angle,skew_angle):\n",
    "    rotated_img = ICV_rotate(img,rotation_angle,True)\n",
    "    rotated_and_skewed_img = ICV_skew_horizontally(rotated_img,skew_angle)\n",
    "    return rotated_and_skewed_img\n",
    "\n",
    "def ICV_skewed_before_rotated_img(img,rotation_angle,skew_angle):\n",
    "    skewed_img = ICV_skew_horizontally(img,skew_angle)\n",
    "    rotated_after_skewed_img = ICV_rotate(skewed_img,rotation_angle,True)\n",
    "    return rotated_after_skewed_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75955272",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(\"rotated_before_skewed.jpg\",ICV_rotated_before_skewed_img(img,20,50))\n",
    "plt.imshow(read_img(\"rotated_before_skewed.jpg\"))\n",
    "cv2.imwrite(\"skewed_before_rotated.jpg\",ICV_skewed_before_rotated_img(img,20,50))\n",
    "plt.imshow(read_img(\"skewed_before_rotated.jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7912e36",
   "metadata": {},
   "source": [
    "## Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1433db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fe7b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_BGR= ICV_load_images_from_folder('Dataset/DatasetA')\n",
    "dataset=[cv2.cvtColor(cv2.cvtColor(img, cv2.COLOR_RGB2GRAY),cv2.COLOR_GRAY2RGB) for img in dataset_BGR]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f909a9-0859-44ec-9c06-fb14c25fa747",
   "metadata": {},
   "source": [
    "This is a helper method created to take the same borders from the input image, avoiding losing data after applying a convolution. \n",
    "\n",
    "\n",
    "This method is going to be used by ICV_convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6319b45-080e-42bb-ab3a-5a8ddd71c0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_same_borders(img,w_kernel,h_kernel):\n",
    "    #Takes the borders of the input images and assigns them to a new matrix with zeros.\n",
    "    img_borders = np.zeros_like(img)\n",
    "    #The numbers of columns and rows to add are defined by the size of the kernel\n",
    "    for i in range(int(w_kernel/2)):\n",
    "        img_borders[i,:] = img[i,:]\n",
    "        img_borders[(len(img)-1)-i,:] = img[(len(img)-1)-i,:]\n",
    "    for i in range(int(h_kernel/2)):\n",
    "        img_borders[:,i] = img[:,i]\n",
    "        img_borders[:,(len(img[0])-1)-i] = img[:,(len(img[0])-1)-i]\n",
    "    return img_borders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c8aecf-b911-4105-a0fe-4f241c8c4535",
   "metadata": {},
   "source": [
    "Here, the convolution method is defined to apply a given kernel to an input image and return the new image. The kernel should be defined as a matrix\n",
    "\n",
    "There are two methods defined, one is applied to BGR images and the second can be applied to GRAY images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb6b27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_convolution(img,kernel):\n",
    "    #Defines the size of the kernel and image\n",
    "    w_kernel,h_kernel = len(kernel),len(kernel[0])\n",
    "    w_img,h_img = len(img),len(img[0])\n",
    "    #assigns the borders from the input to the output image\n",
    "    new_img = ICV_same_borders(img,w_kernel,h_kernel)\n",
    "    w_border = int(w_kernel/2)\n",
    "    h_border = int(h_kernel/2)\n",
    "    #Start iterating over the image by assigning the new value to the center of each window, for each color\n",
    "    for i in range(int(w_kernel/2),len(img)-int(w_kernel/2)):\n",
    "        for j in range(int(h_kernel/2),len(img[0])-int(h_kernel/2)):\n",
    "            new_img[i,j,0] = np.sum(img[i-w_border:i+w_border+1, j-h_border:j+h_border+1,0] * kernel)\n",
    "            new_img[i,j,1] = np.sum(img[i-w_border:i+w_border+1, j-h_border:j+h_border+1,1]* kernel)\n",
    "            new_img[i,j,2] = np.sum(img[i-w_border:i+w_border+1, j-h_border:j+h_border+1,2]* kernel)\n",
    "    return new_img\n",
    "\n",
    "#This method has the same logic than ICV_convolution but is created to work with grayscale images\n",
    "def ICV_convolution_gray(img,kernel):\n",
    "    w_kernel,h_kernel = len(kernel),len(kernel[0])\n",
    "    w_img,h_img = len(img),len(img[0])\n",
    "    new_img = ICV_same_borders(img,w_kernel,h_kernel)\n",
    "    w_border = int(w_kernel/2)\n",
    "    h_border = int(h_kernel/2)\n",
    "    for i in range(int(w_kernel/2),len(img)-int(w_kernel/2)):\n",
    "        for j in range(int(h_kernel/2),len(img[0])-int(h_kernel/2)):\n",
    "            new_img[i,j] = np.sum(img[i-w_border:i+w_border+1, j-h_border:j+h_border+1] * kernel)\n",
    "    return new_img\n",
    "                                               "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e99636",
   "metadata": {},
   "source": [
    "Here is the mean kernel that basically takes the mean in a 3x3 matrix and assign its value to each pixel. This could be used to remove noise from the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7758e670",
   "metadata": {},
   "outputs": [],
   "source": [
    "k2=[[1/9, 1/9 ,1/9],\n",
    "    [1/9, 1/9 ,1/9],\n",
    "    [1/9, 1/9 ,1/9]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1350aa-919b-4d98-ad44-51eef1c962eb",
   "metadata": {},
   "source": [
    "This is another way to remove noise from an image, the median kernel, and works by finding the median in an nxn matrix and assigning its value to each pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d76f58a-53b7-4154-b080-69df665e7871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_denoise_median_filter(img,kernel):\n",
    "    #defines the size of the kernel and image\n",
    "    w_kernel,h_kernel = kernel, kernel\n",
    "    w_img,h_img = len(img),len(img[0])\n",
    "    #create a new matrix with the borders of the input image\n",
    "    new_img = ICV_same_borders(img,w_kernel,h_kernel)\n",
    "    w_border = int(w_kernel/2)\n",
    "    h_border = int(h_kernel/2)\n",
    "    #starts iterating over the image\n",
    "    for i in range(int(w_kernel/2),len(img)-int(w_kernel/2)):\n",
    "        for j in range(int(h_kernel/2),len(img[0])-int(h_kernel/2)):\n",
    "            #for each color it computes the median of an nxn window\n",
    "            new_img[i,j,0] = np.median(img[i-w_border:i+w_border+1, j-h_border:j+h_border+1,0])\n",
    "            new_img[i,j,1] = np.median(img[i-w_border:i+w_border+1, j-h_border:j+h_border+1,1])\n",
    "            new_img[i,j,2] = np.median(img[i-w_border:i+w_border+1, j-h_border:j+h_border+1,2])\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bcc7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(\"Mean_kernel.jpg\",ICV_convolution(dataset_BGR[0],k2))\n",
    "cv2.imwrite(\"Median_kernel.jpg\",ICV_denoise_median_filter(dataset_BGR[0],3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95453e37-a6af-4545-857c-25d3f982b84f",
   "metadata": {},
   "source": [
    "Here both kernels A and B are defined and normalized (In the case of B it is not possible to normalize it because the sum gives 0).\n",
    "\n",
    "\n",
    "After that, each one is applied to the image by using ICV_convolution method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c0ae73",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_A=[[1, 2 ,1],\n",
    "[2, 4 ,2],\n",
    "[1, 2 ,1]]\n",
    "\n",
    "k_A = k_A/np.sum(k_A)\n",
    "\n",
    "k_B = [[0, 1 ,0],\n",
    "[1, -4 ,1],\n",
    "[0, 1 ,0]]\n",
    "\n",
    "img_k_a = ICV_convolution(dataset_BGR[0],k_A)\n",
    "img_k_b = ICV_convolution(dataset_BGR[0],k_B)\n",
    "\n",
    "cv2.imwrite(\"kernel_A.jpg\",ICV_convolution(dataset_BGR[0],k_A))\n",
    "cv2.imwrite(\"kernel_B.jpg\",ICV_convolution(dataset_BGR[0],k_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285cbeb5-05da-4f84-a6d7-e8b9412949f7",
   "metadata": {},
   "source": [
    "Here, I'm going to test what I get if these kernels are combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cbaa6b-db63-4419-a0bb-70e3b9d16b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A followed by A\n",
    "cv2.imwrite(\"kernel_A_followed_by_A.jpg\",ICV_convolution(img_k_a,k_A))\n",
    "#A followed by B\n",
    "cv2.imwrite(\"kernel_A_followed_by_B.jpg\",ICV_convolution(img_k_a,k_B))\n",
    "#B followed by A\n",
    "cv2.imwrite(\"kernel_B_followed_by_A.jpg\",ICV_convolution(img_k_b,k_A))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626760cd-c6a4-4196-9583-5336314c0d42",
   "metadata": {},
   "source": [
    "## Video segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cf1439-c342-4a5e-9956-584ecb4112c6",
   "metadata": {},
   "source": [
    "In this section our input is going to be a video, so the first step is to open it and save each frame in an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2672faa6-e50a-4819-ae03-c1b679d24c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_get_frames(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frames.append(frame)\n",
    "\n",
    "    cap.release()\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2717b2-6b8b-4c72-93e1-780478dea10c",
   "metadata": {},
   "source": [
    "This is a helper method that is going to be used by some of the methods to create an histogram of a given matrix and a number of bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d58abc3-76e1-4fac-8608-2cde861b4c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_histogram(m,bins):\n",
    "    hist = [np.sum(np.where(m==i,1,0)) for i in range(0,bins)]\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08f6a87-eac4-4db9-9b22-3cafb4cf053c",
   "metadata": {},
   "source": [
    "Here, ICV_img_histogram was implemented to create an histogram for each color of a given BGR image and plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f2eeb2-5a01-4311-bccb-ea37ac4d6ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_img_histogram(img,i):\n",
    "    R = img[:,:,2]\n",
    "    G = img[:,:,1]\n",
    "    B = img[:,:,0]\n",
    "    #computes the histogram for each color\n",
    "    R_hist=ICV_histogram(R,256)\n",
    "    G_hist=ICV_histogram(G,256)\n",
    "    B_hist=ICV_histogram(B,256)\n",
    "    bins = range(len(R_hist))\n",
    "    plt.figure()\n",
    "    #Plots each histogram in a single plot\n",
    "    plt.plot(bins,R_hist,label=\"R\",color='r')\n",
    "    plt.plot(bins,G_hist, label=\"G\",color='g')\n",
    "    plt.plot(bins,B_hist,label=\"B\",color='b')\n",
    "    plt.savefig(\"video_hist/fig_\"+str(i)+\".jpg\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7113341b-b9f3-48e4-830f-00379ec1a774",
   "metadata": {},
   "source": [
    "Before executing the code, it's important to make sure all directories exists and if not, create them. This can be done by executing the next cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c053990a-e228-477a-ab0a-adf12a5f6114",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('video_hist', exist_ok=True)\n",
    "os.makedirs('video_hist_intersection', exist_ok=True)\n",
    "os.makedirs('video_hist_intersection_norm', exist_ok=True)\n",
    "os.makedirs('texture_classification', exist_ok=True)\n",
    "os.makedirs('texture_classification/windows', exist_ok=True)\n",
    "os.makedirs('texture_classification/windows_lbp', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1c7b8f-5407-4137-97ad-15f878cdc788",
   "metadata": {},
   "source": [
    "Here I'm going to iterate between all the frames of the video and plot their histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0143e56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = ICV_get_frames('Dataset/DatasetB/DatasetB.avi')\n",
    "for i,frame in enumerate(frames):\n",
    "    ICV_img_histogram(frame,i)\n",
    "    cv2.imwrite(\"video_hist/input_fig_\"+str(i)+\".jpg\",frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a24b704-2f6f-4845-b247-6d0ef48efbec",
   "metadata": {},
   "source": [
    "This method can be used to normalize each color histogram and plot the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9d2e3e-287d-475e-9628-5c08ae9ef53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_normalize(hist):\n",
    "    #get the norm values by dividing each value by the total for each color\n",
    "    hist[0] = np.array(hist[0])/sum(hist[0])\n",
    "    hist[1] = np.array(hist[1])/sum(hist[1])\n",
    "    hist[2] = np.array(hist[2])/sum(hist[2])\n",
    "    return hist\n",
    "def ICV_normalize_gray(hist):\n",
    "    #get the norm values by dividing each value by the total for each color\n",
    "    hist = np.array(hist)/sum(hist)\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733294c6-6407-4018-bb5c-36269933178e",
   "metadata": {},
   "source": [
    "This method finds the intersection between 2 histograms by taking the min value for each bin and saves the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78d081d-bfc2-4990-9909-2afba42427f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_hist_intersection(hist_a,hist_b,bins,actual):\n",
    "    bins=range(bins-1)\n",
    "    #computes the intersection by calculation the min between the histograms in each bin\n",
    "    hist = [[min(hist_a[j][i],hist_b[j][i]) for i in range(len(hist_a[0]))]for j in range(len(hist_a))]\n",
    "    #plots the intersection and saves the image\n",
    "    plt.figure()\n",
    "    plt.plot(bins,hist[0],label=\"B\",color='b')\n",
    "    plt.plot(bins,hist[1],label=\"G\",color='g')\n",
    "    plt.plot(bins,hist[2],label=\"R\",color='r')\n",
    "    plt.savefig(\"video_hist_intersection/fig_\"+str(actual)+\"_\"+str(actual+1)+\".jpg\")\n",
    "    plt.close()\n",
    "    #Normalizes the histogram and saves the plot\n",
    "    norm = ICV_normalize(hist)\n",
    "    plt.figure()\n",
    "    plt.plot(bins,norm[0],label=\"B\",color='b')\n",
    "    plt.plot(bins,norm[1],label=\"G\",color='g')\n",
    "    plt.plot(bins,norm[2],label=\"R\",color='r')\n",
    "    plt.savefig(\"video_hist_intersection_norm/fig_\"+str(actual)+\"_\"+str(actual+1)+\".jpg\")\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc12be1-2c1e-4605-aa16-42880845f63c",
   "metadata": {},
   "source": [
    "Now, I'm going to iterate over each frame of the video, to calculate the individual histogram, the intersection between the actual and the next histogram, and the normalized intersection histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4299535-3aaa-4e62-a3ec-2e65c4f2ccbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(frames)-1):\n",
    "    #defines the frames to compare\n",
    "    actual = frames[i]\n",
    "    next = frames[i+1]\n",
    "    #Gets each single histogram\n",
    "    hist_a = [ICV_histogram(actual[:,:,i],255) for i in range(3)]\n",
    "    hist_b = [ICV_histogram(next[:,:,i],255) for i in range(3)]\n",
    "    #Computes their intersection\n",
    "    ICV_hist_intersection(hist_a,hist_b,256,i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fd688f",
   "metadata": {},
   "source": [
    "### 4. Texture clasification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1977ecd6-d3fb-4934-9b90-b7c7418d7ff1",
   "metadata": {},
   "source": [
    "It's time to apply the definitions and processes of texture classification to finally define to which class belongs each image from the dataset A. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73df7ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "def ICV_load_images_from_folder(folder):\n",
    "    images = {}\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        if img is not None:\n",
    "            images[filename] = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return images\n",
    "\n",
    "images = ICV_load_images_from_folder('Dataset/DatasetA')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ef74cf-1807-4bb4-8156-739f5726bb68",
   "metadata": {},
   "source": [
    "**These are the helper methods that are going to be used by our classificator**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01ba903-53e2-4357-9d74-03eb0cb8be9d",
   "metadata": {},
   "source": [
    "Next method is going to iterate over the pixels of the window to transform each value into binary depending if it is bigger or smaller than the center value. After getting a binary matrix, transforms it into a binary number and finally computes to get the corresponding decimal and assign it to the center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc20cb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_LBP_values(window,count):\n",
    "    size=len(window)\n",
    "    lbp_values = []\n",
    "    global_descriptor = []\n",
    "    pos_window = np.zeros_like(window)\n",
    "    for i in range(1,size-1):\n",
    "        for j in range(1,size-1):\n",
    "            #Extract the sub_img of 3x3 to get the binary and finally the nuew value of the position\n",
    "            sub_img = window[i-1:i+2, j-1:j+2]\n",
    "            #get each value of the subimage clockwise and save them in a list\n",
    "            clock_wise= [[0,0],[0,1],[0,2],[1,2],[2,2],[2,1],[2,0],[1,0]]\n",
    "            sub_img = [sub_img[pos[0],pos[1]] for pos in clock_wise]\n",
    "            #Add 1 if value is bigger than the center, 0 else.\n",
    "            binary = [1 if bit > window[i,j] else 0 for bit in sub_img]\n",
    "            #calculate the binary and assign it to the window\n",
    "            decimal = sum([b<<l for l, b in enumerate(binary[::-1])])\n",
    "            pos_window[i,j]=decimal\n",
    "            lbp_values.append(decimal)\n",
    "    normalized_hist = ICV_LBP_window_hist(pos_window[1:-1,1:-1],count)\n",
    "    return pos_window, normalized_hist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32de6a7-a243-4139-ae39-d95edbbbb083",
   "metadata": {},
   "source": [
    "This method will be used to create and save ICV_histogram of a given LBP window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c772e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_LBP_window_hist(window,count):\n",
    "    #Computes the histogram of the window and normalizes it\n",
    "    lbp_hist=ICV_histogram(window,256)\n",
    "    lbp_hist = ICV_normalize_gray(lbp_hist)\n",
    "    #plots the histogram and saves the image\n",
    "    plt.plot(range(256),lbp_hist,label=\"R\",color='r')\n",
    "    plt.savefig(\"texture_classification/fig_\"+str(count)+\".jpg\")\n",
    "    plt.close()\n",
    "    return lbp_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef05da64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_plot_lbp_hist(hist,name):\n",
    "    #plots a given hist and saves the image\n",
    "    bins = range(len(hist))\n",
    "    plt.plot(bins,hist,label=\"R\",color='r')\n",
    "    plt.savefig(\"texture_classification/fig_\"+str(name)+\".jpg\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c95c57-621a-4764-9db4-5bc3b349526a",
   "metadata": {},
   "source": [
    "By calling this method, the intersection of all histograms can be done to finally get the global descriptor. It the already intersected histograms and the new histogram to intersect. Finally returns the intersection between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae84b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_lbp_intersection(global_descriptor,normalized_hist):\n",
    "    #If it is the first iteration, assigns the histogram of the frame 0, else, computes the min value between the global descriptor and the new frame histfor each bin\n",
    "    if len(global_descriptor) > 1:\n",
    "        hist = [min(global_descriptor[i],normalized_hist[i]) for i in range(len(normalized_hist))]\n",
    "    else:\n",
    "        hist=normalized_hist\n",
    "        \n",
    "    return hist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd5f70b-dd02-4ea9-a0ef-0741eb39a483",
   "metadata": {},
   "source": [
    "This basically returns how far one histogram is from another by calculating their Euclidean distance. This method will be used to compare global histograms and define whether they both belong to the same class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cbc8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_lbp_comparator_euclidean(lbp_hist,lbp_hist2):\n",
    "    return euclidean(lbp_hist,lbp_hist2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f77f033-6d84-409e-9a49-70fd2e376132",
   "metadata": {},
   "source": [
    "**This is the main method that could be used to get the global histogram of a given image and the image divided in windows of w_size size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a8fae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_LBP_windows(source_img,w_size,name):\n",
    "    count=0\n",
    "    #creates a matrix with the same size of the image\n",
    "    source = np.zeros_like(source_img)\n",
    "    global_descriptor_intersec = []\n",
    "    #Starts iterating over the image by each window size\n",
    "    for i in range(0,len(source_img),w_size):\n",
    "        for j in range(0,len(source_img[0]),w_size):\n",
    "            #gets the window\n",
    "            w = source_img[j:j+w_size,i:i+w_size]\n",
    "            #Check if the window has the required size\n",
    "            if len(w)==w_size and len(w[0])==w_size:\n",
    "                #Computes the LBP descriptor and updates the output image\n",
    "                source[j:j+w_size,i:i+w_size],normalized_hist = ICV_LBP_values(w,count)\n",
    "                #computes the intersection between the global and the actual window\n",
    "                global_descriptor_intersec = ICV_lbp_intersection(global_descriptor_intersec,normalized_hist)\n",
    "                count+=1 \n",
    "    ICV_plot_lbp_hist(global_descriptor_intersec,\"global_intersect\"+name)\n",
    "    return source,global_descriptor_intersec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42386b89",
   "metadata": {},
   "source": [
    "Now, by using this class with the name of the image (ubicated in Dataset/DatasetA) is going to return if it is a car or a face by calculating the euclidean distance from face_1 and car_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fb1d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ICV_lbp_classifier():\n",
    "    def __init__(self,window_size):\n",
    "        self.window_size = window_size\n",
    "        #computes the global descriptor for the base face image\n",
    "        self.face_1_lbp,self.base_intersec_face_hist = ICV_LBP_windows(images[\"face-1.jpg\"],window_size,\"face____1\")\n",
    "    \n",
    "    def is_face(self,imgs_name):\n",
    "        self.faces,self.non_faces = [],[]\n",
    "        #Iterates over every image\n",
    "        for img_name in imgs_name:\n",
    "            #Computes its LBP\n",
    "            im_lbp,intersec_hist = ICV_LBP_windows(images[img_name],self.window_size,img_name)\n",
    "            #Calculates the distance to the base image\n",
    "            distance_face = ICV_lbp_comparator_euclidean(intersec_hist,self.base_intersec_face_hist)\n",
    "            #If the distance is less than 0.03 the image is a face\n",
    "            if distance_face < 0.03:\n",
    "                self.faces.append(img_name)\n",
    "            else:\n",
    "                self.non_faces.append(img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5367c28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbp_30 = ICV_lbp_classifier(30)\n",
    "lbp_30.is_face(images.keys())\n",
    "print(\"Faces : {}  Non Faces: {}\".format(lbp_30.faces,lbp_30.non_faces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e551ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbp_200 = ICV_lbp_classifier(100)\n",
    "lbp_200.is_face(images.keys())\n",
    "print(\"Faces : {}  Non Faces: {}\".format(lbp_200.faces,lbp_200.non_faces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd4bf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbp_20 = ICV_lbp_classifier(20)\n",
    "lbp_20.is_face(images.keys())\n",
    "print(\"Faces : {}  Non Faces: {}\".format(lbp_20.faces,lbp_20.non_faces))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82920b6",
   "metadata": {},
   "source": [
    "### Object counting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac7eb2f",
   "metadata": {},
   "source": [
    "In this case, to apply the object counting theory learned in class, we are going to use and AVI file named DatasetC, to extract all its frames and compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0e2b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the folder if it doesn't exist.\n",
    "os.makedirs('object_counting', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccffe62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract each frame and convert them to gray scale\n",
    "frames_to_count = ICV_get_frames('Dataset/DatasetC.avi')\n",
    "frames_to_count =[cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) for img in frames_to_count]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747c3d6e",
   "metadata": {},
   "source": [
    "**Helper method:**\n",
    "\n",
    "\n",
    "This method, give a given image, assigns 255 to every value bigger than a given treshold, else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b663bc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_treshold(s_img,tresh):\n",
    "    treshold_img = np.zeros_like(s_img)\n",
    "    #Iterates over the image\n",
    "    for i in range(len(s_img)):\n",
    "        for j in range(len(s_img[0])):\n",
    "            #Assigns 255 to any pixel greater than the threshold\n",
    "            if s_img[i,j] > tresh:\n",
    "                treshold_img[i,j] = 255\n",
    "            \n",
    "    return treshold_img    \n",
    "\n",
    "def ICV_abs_difference(frame_1,frame_2):\n",
    "\tmatrix = [[abs(int(frame_1[j,i])-int(frame_2[j,i])) for i in range(len(frame_1[0]))]for j in range(len(frame_1))]\n",
    "\treturn matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0564d2e1",
   "metadata": {},
   "source": [
    "Now to calculate the pixel-by-pixel frame differencing and get the tresholded image, the next method sould be executed with a list of frames and an optional flag to compare all the frames with an specific position (the index of the frame should be passed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1a98e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_frame_differencing(frames_to_diff,frame_base=-1,):\n",
    "    #Get the number of frames to be compared\n",
    "    n_frames = len(frames_to_diff)\n",
    "    #in case frame_base is different to -1, every frame is compared to the specified position by getting the absolute\n",
    "    #difference and each value is compared to the threshold defined, to finally get the image with the detected objects.\n",
    "    if frame_base != -1 and frame_base <= n_frames:\n",
    "        for i in range(n_frames):\n",
    "            frame_1,frame_2 = frames_to_diff[frame_base],frames_to_diff[i]\n",
    "            abs_difference = [[abs(int(frame_1[j,i])-int(frame_2[j,i])) for i in range(len(frame_1[0]))]for j in range(len(frame_1))]\n",
    "            abs_difference= np.array(abs_difference,dtype=np.uint8)\n",
    "            treshold_img = ICV_treshold(np.array(abs_difference),25)\n",
    "            cv2.imwrite(\"object_counting/_specific_frame\"+str(frame_base)+\"_and_\"+str(i)+\".jpg\",cv2.cvtColor(treshold_img, cv2.COLOR_GRAY2RGB))\n",
    "    else:\n",
    "        #else, frame_base is -1, every frame is compared to next frame\n",
    "        for i in range(n_frames-1):\n",
    "            frame_1,frame_2 = frames_to_diff[i],frames_to_diff[i+1]\n",
    "            abs_difference = [[abs(int(frame_1[j,i])-int(frame_2[j,i])) for i in range(len(frame_1[0]))]for j in range(len(frame_1))]\n",
    "            abs_difference= np.array(abs_difference,dtype=np.uint8)\n",
    "            treshold_img = ICV_treshold(np.array(abs_difference),25)\n",
    "            cv2.imwrite(\"object_counting/frames_\"+str(i)+\"_and_\"+str(i+1)+\".jpg\",cv2.cvtColor(treshold_img, cv2.COLOR_GRAY2RGB))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d7fa65",
   "metadata": {},
   "source": [
    "This line generates all the images with the treshold of the difference between the frame 0 and each frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e47918c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ICV_frame_differencing(frames_to_count,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396baeed",
   "metadata": {},
   "source": [
    "This line generates all the images with the treshold of the difference between all consecutived frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ebbde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ICV_frame_differencing(frames_to_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49ca378-1d98-4ab0-a989-eb848c24df8c",
   "metadata": {},
   "source": [
    "Next method could be used to get the background of a given list of frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e434ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_get_back(frames):\n",
    "    #Assigns the first frame\n",
    "    bg=frames[0]\n",
    "    n_frames = len(frames)\n",
    "    w = 0.01\n",
    "    #starts iterating over each frame\n",
    "    for i in range(1,n_frames):\n",
    "        frame_1 = frames[i]\n",
    "        #get the difference between consecutive images\n",
    "        abs_difference_matrix = np.array(ICV_abs_difference(bg,frame_1))\n",
    "        treshold_matrix = ICV_treshold(np.array(abs_difference_matrix,dtype=np.uint8),25)\n",
    "        #Computed the weighted average given more weight to the background\n",
    "        bg = (bg* (1-(0.02)))+ (abs_difference_matrix*(0.02))\n",
    "        w += 0.01\n",
    "   \n",
    "    bg=bg/w\n",
    "    return bg\n",
    "cv2.imwrite(\"object_counting/background.jpg\",np.matrix(ICV_get_back(frames_to_count),dtype=np.uint8))\n",
    "background = ICV_get_back(frames_to_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d73d641-8c23-40ce-9a51-3ea68b62c824",
   "metadata": {},
   "source": [
    "Next method will count the number of objects of a given threshold matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a16ba2-65e8-4adf-aa67-b95d68d2c7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_object_count(tresh_img):\n",
    "    #objects and their pixels\n",
    "    objects = dict()\n",
    "\n",
    "    for i in range(tresh_img.shape[0]):\n",
    "        for j in range(tresh_img.shape[1]):\n",
    "            #check if the pixel is white\n",
    "            if tresh_img[i, j] == 255:\n",
    "                is_new = True\n",
    "                detected_objs = []\n",
    "                #If there are already found objects finds how near is from them\n",
    "                for obj in objects.keys():\n",
    "                    is_new = ICV_is_near(objects[obj],i,j)\n",
    "                    if not is_new:\n",
    "                        detected_objs.append(obj)\n",
    "                #If the pixel is not near to any found object, add it as a new object to the list            \n",
    "                if is_new == True:\n",
    "                    objects[len(objects)+1] = [(i, j)]\n",
    "                #If it belongs to any object adds it to the list \n",
    "                else:\n",
    "                    if len(detected_objs) > 1:\n",
    "                        for object_d in detected_objs[1:]:\n",
    "                            objects[detected_objs[0]].extend(objects[object_d])\n",
    "                            objects.pop(object_d)\n",
    "                    else:\n",
    "                        if (i,j) not in objects[detected_objs[0]]:\n",
    "                            objects[detected_objs[0]].append((i,j))\n",
    "\n",
    "    count = sum([1 for key in objects.keys() if len(objects[key]) > 50])\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0930cc6-237b-4ca0-90fb-04f1f5aa3ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_is_near(objects_obj,i,j):\n",
    "    is_newv=True\n",
    "    for r,c in objects_obj:\n",
    "            #if the pixel is near to an object by 4 or less pixels, it is not consider as a new object\n",
    "        if abs(i - r) <= 3 and abs(j - c) <= 3:\n",
    "            is_newv = False\n",
    "            break\n",
    "    return is_newv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ae6b2a-4f79-48ac-81d3-5d0ad88895d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"object_counting/_specific_frame0_and_1.jpg\")\n",
    "image=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf905ec1-0eb3-42cf-ae0b-2fa8ab882360",
   "metadata": {},
   "source": [
    "Here, I'm going to iterate over each frame to get the number of moving objects in all of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1619d20d-1bcd-48a9-bdc9-d6f8d3f68754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_objects_plot(frames,background_im):\n",
    "    count = np.zeros(len(frames))\n",
    "    for i in range(len(frames)):\n",
    "            frame_2 = frames[i]\n",
    "        #Computes he difference and the threshold of 2 consecutive frames\n",
    "            abs_difference = [[abs(int(background_im[j,i])-int(frame_2[j,i])) for i in range(len(frame_2[0]))]for j in range(len(frame_2))]\n",
    "            abs_difference= np.array(abs_difference,dtype=np.uint8)\n",
    "            treshold_img = ICV_treshold(np.array(abs_difference),25)\n",
    "            cv2.imwrite(\"object_counting/count\"+str(i)+\".jpg\",cv2.cvtColor(treshold_img, cv2.COLOR_GRAY2RGB))\n",
    "        #By using the defined method, count the number of objects and adds it to the count list\n",
    "            count[i] = ICV_object_count(treshold_img)                       \n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b4de80-4512-459e-8fac-eb26420cb52e",
   "metadata": {},
   "source": [
    "Here im going to execute the above code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65156fb-6e56-4a06-b303-6b5e46b169c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_count = ICV_objects_plot(frames_to_count,frames_to_count[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06ed20d-c24c-49df-a1d9-f5c236d22e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(140),objects_count)\n",
    "plt.savefig(\"count_object_graph.jpg\")\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
